{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was the code used to generate the samples used in the final model. It also includes prototypes of the models implmented in the final not book. The most important piece of code was the loop that went over the data file and parsed out the categories of interest. This was the biggest bottleneck in modeling as running this block would take between three and five hours. By saving the results into numpy arrays, the results could be quickly accessed in the final notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacking a non-streaming CNN Model\n",
    "\n",
    "import cv2\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "# Any results you write to the current directory are saved as output. \n",
    "#KS Ask about this line\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from skimage.data import imread   # or, whatever image library you prefer\n",
    "import multiprocessing as mp      # will come in handy due to the size of the data\n",
    "import bson\n",
    "import io\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import itertools\n",
    "from tqdm import *\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking specifically over the range for the following categories, while aready numeric\n",
    "# I will use label encoder to take out any sense of ordinal value \n",
    "\n",
    "targets = [1000003437, 1000003407, 1000003400, 1000003404, 1000003402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = bson.decode_file_iter(open('/Volumes/G-DRIVE mobile/Image_Data_DSI/train.bson', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data and convert it into an iterable version of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 500/6728 [02:00<23:14,  4.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 999/6728 [05:05<42:56,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1499/6728 [09:08<46:47,  1.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1999/6728 [13:59<53:24,  1.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2499/6728 [20:25<53:57,  1.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2999/6728 [28:30<1:06:46,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3499/6728 [37:14<1:00:55,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3999/6728 [49:15<1:07:37,  1.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4499/6728 [1:01:57<57:52,  1.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4999/6728 [1:16:29<58:06,  2.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 5499/6728 [1:33:27<45:07,  2.20s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 5999/6728 [1:52:07<30:44,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6499/6728 [2:12:45<09:24,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 6660/6728 [2:20:25<02:59,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# This is the method to stream through the test set and pull out the data \n",
    "X = []\n",
    "y = []\n",
    "counter=0\n",
    "with tqdm(total=6728) as pbar:\n",
    "    for i in range(6009411):\n",
    "        piece = next(it)\n",
    "        if piece.get('category_id') in targets:\n",
    "            counter = counter + 1\n",
    "            if counter % 500 == 0: \n",
    "                print(counter)\n",
    "            img = piece.get('imgs')[0]\n",
    "            pic = io.BytesIO(img.get('picture', None))\n",
    "            im = imread(pic)\n",
    "            im = im.astype('float32') / 255.0\n",
    "            X.append(im)\n",
    "#             np.array(X)\n",
    "\n",
    "            category = piece.get('category_id', \"\")\n",
    "            label = label_encoder.transform([category])\n",
    "            y.append(label)\n",
    "#             np.array(y)\n",
    "            pbar.update()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6660"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6660"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X =np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6280, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('wine_Xtrain.npy', 'wb') as np_out:\n",
    "    np.save(np_out,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('wine_ytrain.npy', 'wb') as np_yout:\n",
    "    np.save(np_yout,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making these into arrays may have created a problem. Can try to convert again\n",
    "# or open new notebook and run again without the array line, hopefully will be faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2003)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 180, 180, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 180, 180, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4995 samples, validate on 1665 samples\n",
      "Epoch 1/2\n",
      "4995/4995 [==============================] - 211s 42ms/step - loss: 0.9460 - acc: 0.6593 - val_loss: 0.7449 - val_acc: 0.7357\n",
      "Epoch 2/2\n",
      "4995/4995 [==============================] - 202s 41ms/step - loss: 0.6015 - acc: 0.7810 - val_loss: 0.5980 - val_acc: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145d2f320>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(180, 180, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(16, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"KPS_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 176, 176, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 88, 88, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 85, 85, 16)        8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 28224)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                903200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 914,005\n",
      "Trainable params: 914,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4995 samples, validate on 1665 samples\n",
      "Epoch 1/3\n",
      "4995/4995 [==============================] - 206s 41ms/step - loss: 0.4447 - acc: 0.8414 - val_loss: 0.5652 - val_acc: 0.8168\n",
      "Epoch 2/3\n",
      "4995/4995 [==============================] - 203s 41ms/step - loss: 0.3358 - acc: 0.8879 - val_loss: 0.5876 - val_acc: 0.8204\n",
      "Epoch 3/3\n",
      "4995/4995 [==============================] - 202s 40ms/step - loss: 0.2541 - acc: 0.9107 - val_loss: 0.6489 - val_acc: 0.8126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146cd4e10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"KPS_Model_1_5epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now will generate true out of sample data from the remaining images in the set, will\n",
    "# loop through again, since there are 7898 images in the set, know there are 1,298 unseen images\n",
    "# in teh remaining ~1mm images. I will re-run the loop above, since it is an iterator, it will\n",
    "# pick up on data where left off before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1298 [00:20<03:25,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 200/1298 [00:44<04:47,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 299/1298 [01:10<03:29,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 399/1298 [01:40<05:08,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 500/1298 [02:13<04:26,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 600/1298 [02:51<05:18,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 699/1298 [03:29<04:11,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 799/1298 [04:16<03:34,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 899/1298 [05:05<03:26,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 999/1298 [06:00<02:44,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1099/1298 [06:58<02:05,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1199/1298 [07:59<01:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1256/1298 [08:38<00:26,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is the method to stream through the test set and pull out the data \n",
    "Xt = []\n",
    "yt = []\n",
    "counter=0\n",
    "with tqdm(total=1298) as pbar:\n",
    "    for i in range(1060480):\n",
    "        piece = next(it)\n",
    "        if piece.get('category_id') in targets:\n",
    "            counter = counter + 1\n",
    "            if counter % 100 == 0: \n",
    "                print(counter)\n",
    "            img = piece.get('imgs')[0]\n",
    "            pic = io.BytesIO(img.get('picture', None))\n",
    "            im = imread(pic)\n",
    "            im = im.astype('float32') / 255.0\n",
    "            Xt.append(im)\n",
    "#             np.array(Xt)\n",
    "\n",
    "            category = piece.get('category_id', \"\")\n",
    "            label = label_encoder.transform([category])\n",
    "            yt.append(label)\n",
    "#             np.array(yt)\n",
    "            pbar.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7916"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yt) + len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt = np.array(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yt = to_categorical(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good spot check, y and T are seperate!\n",
    "# left five spaces on end of next(it) to verify was at end. So now the full dataset for \n",
    "# images I want to classify saved as variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = np.array(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('wine_Xtest.npy', 'wb') as np_test_out:\n",
    "    np.save(np_test_out, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('wine_ytest.npy', 'wb') as np_test_you:\n",
    "    np.save(np_test_you, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds= model.predict(Xt,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.89779472e-01,   2.96259169e-02,   2.67489795e-05,\n",
       "          3.84298146e-01,   9.62697566e-02],\n",
       "       [  8.62724960e-01,   6.02738990e-04,   1.68416295e-06,\n",
       "          8.58174681e-05,   1.36584848e-01],\n",
       "       [  6.61207247e-04,   7.28846790e-05,   4.46278449e-07,\n",
       "          9.99263346e-01,   2.17029537e-06],\n",
       "       ..., \n",
       "       [  9.99141932e-01,   8.37529544e-04,   8.61768399e-07,\n",
       "          1.83649317e-05,   1.36255176e-06],\n",
       "       [  4.72475514e-02,   1.32567540e-01,   1.95268964e-04,\n",
       "          7.50540793e-01,   6.94488660e-02],\n",
       "       [  9.98574495e-01,   1.41062087e-03,   1.40797583e-05,\n",
       "          7.64620722e-07,   9.57362687e-08]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confusion_matrix(yt, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6660 samples, validate on 1256 samples\n",
      "Epoch 1/5\n",
      "6660/6660 [==============================] - 273s 41ms/step - loss: 0.3014 - acc: 0.9029 - val_loss: 0.5873 - val_acc: 0.8368\n",
      "Epoch 2/5\n",
      "6660/6660 [==============================] - 254s 38ms/step - loss: 0.1980 - acc: 0.9320 - val_loss: 0.5828 - val_acc: 0.8503\n",
      "Epoch 3/5\n",
      "6660/6660 [==============================] - 398s 60ms/step - loss: 0.1480 - acc: 0.9483 - val_loss: 0.6331 - val_acc: 0.8463\n",
      "Epoch 4/5\n",
      "6660/6660 [==============================] - 260s 39ms/step - loss: 0.1198 - acc: 0.9583 - val_loss: 0.7281 - val_acc: 0.8360\n",
      "Epoch 5/5\n",
      "6660/6660 [==============================] - 253s 38ms/step - loss: 0.0939 - acc: 0.9704 - val_loss: 0.7623 - val_acc: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146d01240>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_data=(Xt, yt), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the prediction classes? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4995 samples, validate on 1665 samples\n",
      "Epoch 1/3\n",
      "4995/4995 [==============================] - 147s 29ms/step - loss: 0.9028 - acc: 0.6627 - val_loss: 0.7322 - val_acc: 0.7249\n",
      "Epoch 2/3\n",
      "4995/4995 [==============================] - 138s 28ms/step - loss: 0.5998 - acc: 0.7846 - val_loss: 0.5555 - val_acc: 0.8000\n",
      "Epoch 3/3\n",
      "4995/4995 [==============================] - 136s 27ms/step - loss: 0.4511 - acc: 0.8468 - val_loss: 0.5349 - val_acc: 0.8180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145b3d860>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Second Model\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(16, (2, 2), input_shape=(180, 180, 3), activation='relu'))\n",
    "model2.add(MaxPool2D((2,2)))\n",
    "model2.add(Conv2D(32, (4,4), activation='relu'))\n",
    "model2.add(MaxPool2D((2, 2)))\n",
    "model2.add(Conv2D(64, (4,4), activation='relu'))\n",
    "model2.add(MaxPool2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 179, 179, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 89, 89, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 86, 86, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 40, 40, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                819232    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 860,661\n",
      "Trainable params: 860,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4995 samples, validate on 1665 samples\n",
      "Epoch 1/2\n",
      "4995/4995 [==============================] - 141s 28ms/step - loss: 0.3567 - acc: 0.8727 - val_loss: 0.5132 - val_acc: 0.8342\n",
      "Epoch 2/2\n",
      "4995/4995 [==============================] - 138s 28ms/step - loss: 0.2780 - acc: 0.9047 - val_loss: 0.5008 - val_acc: 0.8486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146d01cc0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save(\"Model2_5_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6660 samples, validate on 1256 samples\n",
      "Epoch 1/5\n",
      "6660/6660 [==============================] - 182s 27ms/step - loss: 0.3015 - acc: 0.8988 - val_loss: 0.4275 - val_acc: 0.8623\n",
      "Epoch 2/5\n",
      "6660/6660 [==============================] - 172s 26ms/step - loss: 0.2149 - acc: 0.9255 - val_loss: 0.4629 - val_acc: 0.8694\n",
      "Epoch 3/5\n",
      "6660/6660 [==============================] - 173s 26ms/step - loss: 0.1802 - acc: 0.9390 - val_loss: 0.5875 - val_acc: 0.8264\n",
      "Epoch 4/5\n",
      "6660/6660 [==============================] - 174s 26ms/step - loss: 0.1396 - acc: 0.9505 - val_loss: 0.5462 - val_acc: 0.8678\n",
      "Epoch 5/5\n",
      "6660/6660 [==============================] - 171s 26ms/step - loss: 0.1204 - acc: 0.9596 - val_loss: 0.6231 - val_acc: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1474c4be0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y, validation_data=(Xt, yt), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Had to fix ytests changes made in seperate notebook "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
