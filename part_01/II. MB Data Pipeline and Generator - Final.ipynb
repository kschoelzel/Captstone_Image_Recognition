{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacking a non-streaming CNN Modelfrom subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from skimage.data import imread   \n",
    "import multiprocessing as mp      \n",
    "import bson\n",
    "import io\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import itertools\n",
    "from tqdm import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking specifically over the range for the following categories, while aready numeric\n",
    "# I will use label encoder to take out any sense of ordinal value \n",
    "\n",
    "# photography books, auto-fuses, headboards, hinges, lotion\n",
    "targets = [1000014042, 1000005888, 1000015754, 1000002844, 1000003988]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = bson.decode_file_iter(open('/Volumes/G-DRIVE mobile/Image_Data_DSI/train.bson', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data and convert it into an iterable version of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 250/6728 [01:12<26:23,  4.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 500/6728 [02:21<32:58,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 749/6728 [03:50<34:43,  2.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 999/6728 [05:28<28:51,  3.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1249/6728 [07:15<38:41,  2.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1499/6728 [09:19<43:07,  2.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1749/6728 [11:37<47:46,  1.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1999/6728 [14:12<47:33,  1.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2249/6728 [17:11<55:20,  1.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2499/6728 [20:37<1:02:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2749/6728 [24:17<1:00:32,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2999/6728 [28:21<55:07,  1.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3249/6728 [32:40<1:01:56,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3499/6728 [37:03<53:58,  1.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3749/6728 [41:44<58:23,  1.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3999/6728 [47:14<1:00:34,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 4249/6728 [53:05<56:54,  1.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4499/6728 [59:45<1:01:25,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 4749/6728 [1:06:39<59:58,  1.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4999/6728 [1:13:57<45:09,  1.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 5249/6728 [1:21:28<52:27,  2.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 5499/6728 [1:30:07<47:03,  2.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 5749/6728 [1:40:06<35:48,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 5999/6728 [1:50:43<30:31,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 6249/6728 [2:12:40<51:53,  6.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6499/6728 [2:30:38<11:25,  2.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 6633/6728 [2:44:40<12:23,  7.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# This is the method to stream through the test set and pull out the data \n",
    "X = []\n",
    "y = []\n",
    "counter=0\n",
    "with tqdm(total=6728) as pbar:\n",
    "    for i in range(6009411):\n",
    "        piece = next(it)\n",
    "        if piece.get('category_id') in targets:\n",
    "            counter = counter + 1\n",
    "            if counter % 250 == 0: \n",
    "                print(counter)\n",
    "            img = piece.get('imgs')[0]\n",
    "            pic = io.BytesIO(img.get('picture', None))\n",
    "            im = imread(pic)\n",
    "            im = im.astype('float32') / 255.0\n",
    "            X.append(im)\n",
    "            np.array(X)\n",
    "\n",
    "            category = piece.get('category_id', \"\")\n",
    "            label = label_encoder.transform([category])\n",
    "            y.append(label)\n",
    "            np.array(y)\n",
    "            pbar.update()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6633"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X =np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33165"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('MB_Xtrain.npy', 'wb') as np_mbX_out:\n",
    "    np.save(np_mbX_out,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33165, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('MB_ytrain.npy', 'wb') as np_mby_out:\n",
    "    np.save(np_mby_out,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2003)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 180, 180, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 180, 180, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4974 samples, validate on 1659 samples\n",
      "Epoch 1/2\n",
      "4974/4974 [==============================] - 217s 44ms/step - loss: 0.9476 - acc: 0.6711 - val_loss: 0.7067 - val_acc: 0.7951\n",
      "Epoch 2/2\n",
      "4974/4974 [==============================] - 215s 43ms/step - loss: 0.5876 - acc: 0.8070 - val_loss: 0.5957 - val_acc: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117d8d780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(180, 180, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(16, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"KPS_diff_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 176, 176, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 88, 88, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 16)        8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28224)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                903200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 914,005\n",
      "Trainable params: 914,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4974 samples, validate on 1659 samples\n",
      "Epoch 1/3\n",
      "4974/4974 [==============================] - 218s 44ms/step - loss: 0.3653 - acc: 0.8790 - val_loss: 0.6420 - val_acc: 0.8125\n",
      "Epoch 2/3\n",
      "4974/4974 [==============================] - 209s 42ms/step - loss: 0.2428 - acc: 0.9176 - val_loss: 0.6691 - val_acc: 0.8342\n",
      "Epoch 3/3\n",
      "4974/4974 [==============================] - 210s 42ms/step - loss: 0.1369 - acc: 0.9564 - val_loss: 0.7732 - val_acc: 0.8385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x105f9b7f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"KPS_diff_Model_1_5epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now will generate true out of sample data from the remaining images in the set, will\n",
    "# loop through again, since there are 7898 images in the set, know there are 1,298 unseen images\n",
    "# in teh remaining ~1mm images. I will re-run the loop above, since it is an iterator, it will\n",
    "# pick up on data where left off before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 499/1283 [02:11<03:45,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 999/1283 [05:16<01:50,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1283/1283 [07:16<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is the method to stream through the test set and pull out the data \n",
    "Xt = []\n",
    "yt = []\n",
    "counter=0\n",
    "with tqdm(total=1283) as pbar:\n",
    "    for i in range(1060480):\n",
    "        piece = next(it)\n",
    "        if piece.get('category_id') in targets:\n",
    "            counter = counter + 1\n",
    "            if counter % 500 == 0: \n",
    "                print(counter)\n",
    "            img = piece.get('imgs')[0]\n",
    "            pic = io.BytesIO(img.get('picture', None))\n",
    "            im = imread(pic)\n",
    "            im = im.astype('float32') / 255.0\n",
    "            Xt.append(im)\n",
    "            np.array(Xt)\n",
    "\n",
    "            category = piece.get('category_id', \"\")\n",
    "            label = label_encoder.transform([category])\n",
    "            yt.append(label)\n",
    "            np.array(yt)\n",
    "            pbar.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33165"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34448"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yt) + len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt = np.array(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yt = to_categorical(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good spot check, y and T are seperate!\n",
    "# left five spaces on end of next(it) to verify was at end. So now the full dataset for \n",
    "# images I want to classify saved as variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = np.array(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('MB_Xtest.npy', 'wb') as np_mbXt_out:\n",
    "    np.save(np_mbXt_out, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('MB_ytest.npy', 'wb') as np_mbyt_out:\n",
    "    np.save(np_mbyt_out, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds= model.predict(Xt,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.01999826e-04,   3.62010795e-08,   9.87386167e-01,\n",
       "          1.22194225e-02,   9.22527761e-05],\n",
       "       [  3.58475864e-01,   2.70820572e-04,   4.68214303e-02,\n",
       "          1.07964955e-01,   4.86466944e-01],\n",
       "       [  5.86078912e-02,   1.27363382e-04,   9.03451025e-01,\n",
       "          2.44561136e-02,   1.33576673e-02],\n",
       "       ..., \n",
       "       [  2.52697532e-06,   3.28857097e-09,   2.27253771e-08,\n",
       "          9.99997497e-01,   2.98068379e-08],\n",
       "       [  1.17816293e-04,   3.58062935e-05,   4.66740785e-05,\n",
       "          8.03596806e-03,   9.91763711e-01],\n",
       "       [  9.95701492e-01,   4.28461902e-07,   2.44033663e-03,\n",
       "          3.74378898e-04,   1.48338347e-03]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confusion_matrix(yt, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6633 samples, validate on 1283 samples\n",
      "Epoch 1/5\n",
      "6633/6633 [==============================] - 276s 42ms/step - loss: 0.3188 - acc: 0.9166 - val_loss: 0.6329 - val_acc: 0.8472\n",
      "Epoch 2/5\n",
      "6633/6633 [==============================] - 264s 40ms/step - loss: 0.1336 - acc: 0.9597 - val_loss: 0.7048 - val_acc: 0.8426\n",
      "Epoch 3/5\n",
      "6633/6633 [==============================] - 5834s 880ms/step - loss: 0.0681 - acc: 0.9807 - val_loss: 0.7534 - val_acc: 0.8574\n",
      "Epoch 4/5\n",
      "6633/6633 [==============================] - 885s 133ms/step - loss: 0.0380 - acc: 0.9902 - val_loss: 0.9029 - val_acc: 0.8574\n",
      "Epoch 5/5\n",
      "6633/6633 [==============================] - 858s 129ms/step - loss: 0.0431 - acc: 0.9882 - val_loss: 1.1186 - val_acc: 0.8519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x105e1ce48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_data=(Xt, yt), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the prediction classes? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4974 samples, validate on 1659 samples\n",
      "Epoch 1/3\n",
      "4974/4974 [==============================] - 153s 31ms/step - loss: 0.9046 - acc: 0.6799 - val_loss: 0.7160 - val_acc: 0.7860\n",
      "Epoch 2/3\n",
      "4974/4974 [==============================] - 142s 29ms/step - loss: 0.5912 - acc: 0.8044 - val_loss: 0.5693 - val_acc: 0.8294\n",
      "Epoch 3/3\n",
      "4974/4974 [==============================] - 142s 28ms/step - loss: 0.4277 - acc: 0.8552 - val_loss: 0.5968 - val_acc: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c604c50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Second Model\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(16, (2, 2), input_shape=(180, 180, 3), activation='relu'))\n",
    "model2.add(MaxPool2D((2,2)))\n",
    "model2.add(Conv2D(32, (4,4), activation='relu'))\n",
    "model2.add(MaxPool2D((2, 2)))\n",
    "model2.add(Conv2D(64, (4,4), activation='relu'))\n",
    "model2.add(MaxPool2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 179, 179, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 89, 89, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 86, 86, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 40, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                819232    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 860,661\n",
      "Trainable params: 860,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4974 samples, validate on 1659 samples\n",
      "Epoch 1/2\n",
      "4974/4974 [==============================] - 147s 29ms/step - loss: 0.2693 - acc: 0.9115 - val_loss: 0.4931 - val_acc: 0.8608\n",
      "Epoch 2/2\n",
      "4974/4974 [==============================] - 142s 28ms/step - loss: 0.1706 - acc: 0.9413 - val_loss: 0.4705 - val_acc: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c8f8cc0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save(\"Model2_diff_5_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6633 samples, validate on 1283 samples\n",
      "Epoch 1/5\n",
      "6633/6633 [==============================] - 185s 28ms/step - loss: 0.2282 - acc: 0.9317 - val_loss: 0.5094 - val_acc: 0.8613\n",
      "Epoch 2/5\n",
      "6633/6633 [==============================] - 181s 27ms/step - loss: 0.1297 - acc: 0.9614 - val_loss: 0.5506 - val_acc: 0.8792\n",
      "Epoch 3/5\n",
      "6633/6633 [==============================] - 180s 27ms/step - loss: 0.0786 - acc: 0.9783 - val_loss: 0.6175 - val_acc: 0.8862\n",
      "Epoch 4/5\n",
      "6633/6633 [==============================] - 1824s 275ms/step - loss: 0.0462 - acc: 0.9858 - val_loss: 0.8877 - val_acc: 0.8504\n",
      "Epoch 5/5\n",
      "6633/6633 [==============================] - 185s 28ms/step - loss: 0.0638 - acc: 0.9803 - val_loss: 0.6877 - val_acc: 0.8644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x105e4d198>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y, validation_data=(Xt, yt), epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
